{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 2776)\n",
      "(48000, 2)\n",
      "(48000,)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.load(\"training_data.npy\").astype(np.float32)\n",
    "categories = np.load(\"categories.npy\")\n",
    "valid_periods=np.load(\"valid_periods.npy\")\n",
    "categories_unique = np.unique(categories)\n",
    "\n",
    "print(training_data.shape)\n",
    "print(valid_periods.shape)\n",
    "print(categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(category, window_length=200, telescope=18, from_start=True):\n",
    "    dataset = []\n",
    "\n",
    "    skipped_samples = 0\n",
    "    dataset_window_length = window_length + telescope\n",
    "    sample_map = categories==category\n",
    "    \n",
    "    valid_perios_for_category = valid_periods[sample_map]\n",
    "    training_data_for_category = training_data[sample_map]\n",
    "\n",
    "    for i in range(len(valid_perios_for_category)):\n",
    "        from_time = valid_perios_for_category[i,0]\n",
    "        to_time = valid_perios_for_category[i,1]\n",
    "        if(to_time-from_time<dataset_window_length):\n",
    "            skipped_samples+=1\n",
    "            continue\n",
    "        if(from_start):\n",
    "            sample = training_data_for_category[i][from_time:from_time+dataset_window_length]\n",
    "        else:\n",
    "            sample = training_data_for_category[i][to_time-dataset_window_length:to_time]\n",
    "        dataset.append(sample)\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "    dataset = dataset.reshape((dataset.shape[0], dataset.shape[1], 1))\n",
    "    print(\"Skipped samples: \", skipped_samples)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length=200\n",
    "telescope=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped samples:  1891\n",
      "Skipped samples:  7567\n",
      "Skipped samples:  5100\n",
      "Skipped samples:  4507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped samples:  6821\n",
      "Skipped samples:  178\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "for category in categories_unique:\n",
    "    dataset = build_dataset(category, window_length=window_length, telescope=telescope)\n",
    "    datasets[category] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CONV_LSTM_model(input_shape, output_shape):\n",
    "    # Ensure the input time steps are at least as many as the output time steps\n",
    "    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n",
    "\n",
    "    # Define the input layer with the specified shape\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # Add a Bidirectional LSTM layer with 64 units\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n",
    "\n",
    "    # Add a 1D Convolution layer with 128 filters and a kernel size of 3\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu', name='conv')(x)\n",
    "\n",
    "    # Add a final Convolution layer to match the desired output shape\n",
    "    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', name='output_layer')(x)\n",
    "\n",
    "    # Calculate the size to crop from the output to match the output shape\n",
    "    crop_size = output_layer.shape[1] - output_shape[0]\n",
    "\n",
    "    # Crop the output to the desired length\n",
    "    output_layer = tfkl.Cropping1D((0, crop_size), name='cropping')(output_layer)\n",
    "\n",
    "    # Construct the model by connecting input and output layers\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
    "\n",
    "    # Compile the model with Mean Squared Error loss and Adam optimizer\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(), metrics=['mse', \"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(datasets):\n",
    "    for category in categories_unique:\n",
    "        print(\"Training model for category: \", category)\n",
    "        X_data = datasets[category]\n",
    "        X_train, y_train = X_data[:, :-telescope], X_data[:, -telescope:]\n",
    "\n",
    "        input_shape = X_train.shape[1:]\n",
    "        output_shape = y_train.shape[1:]\n",
    "        batch_size = 64\n",
    "        epochs = 200\n",
    "\n",
    "        model = build_CONV_LSTM_model(input_shape, output_shape)\n",
    "        history = model.fit(\n",
    "            x = X_train,\n",
    "            y = y_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            validation_split=.1,\n",
    "            callbacks = [\n",
    "                tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
    "                tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
    "            ]\n",
    "        ).history\n",
    "\n",
    "        print(\"Model \" + category + \" MSE: \"+ str(history[\"val_mse\"][-1]))\n",
    "        print(\"Model \" + category + \" MAE: \" + str(history[\"val_mae\"][-1]))\n",
    "\n",
    "        model.save(\"Vanilla_200Window/Vanilla_\"+category)\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for category:  A\n",
      "Epoch 1/200\n",
      "54/54 [==============================] - 10s 50ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.2436 - val_loss: 0.0518 - val_mse: 0.0518 - val_mae: 0.1883 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1873 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1887 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1872 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1858 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1847 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1870 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1833 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1873 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1837 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1950 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1826 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1944 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1820 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1895 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1657 - val_loss: 0.0551 - val_mse: 0.0551 - val_mae: 0.1892 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1625 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1882 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.1886 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1866 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1844 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1855 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1843 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1887 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1816 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1866 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1823 - val_loss: 0.0525 - val_mse: 0.0525 - val_mae: 0.1874 - lr: 1.0000e-04\n",
      "Model A MSE: 0.05247316509485245\n",
      "Model A MAE: 0.1873892843723297\n",
      "Training model for category:  B\n",
      "Epoch 1/200\n",
      "49/49 [==============================] - 5s 50ms/step - loss: 0.1344 - mse: 0.1344 - mae: 0.3000 - val_loss: 0.0628 - val_mse: 0.0628 - val_mae: 0.2042 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0796 - mse: 0.0796 - mae: 0.2413 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.2052 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0790 - mse: 0.0790 - mae: 0.2413 - val_loss: 0.0772 - val_mse: 0.0772 - val_mae: 0.2200 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0783 - mse: 0.0783 - mae: 0.2406 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.2084 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0781 - mse: 0.0781 - mae: 0.2398 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.2137 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0743 - mse: 0.0743 - mae: 0.2319 - val_loss: 0.0442 - val_mse: 0.0442 - val_mae: 0.1644 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0746 - mse: 0.0746 - mae: 0.2280 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.2136 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0786 - mse: 0.0786 - mae: 0.2412 - val_loss: 0.0714 - val_mse: 0.0714 - val_mae: 0.2123 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0782 - mse: 0.0782 - mae: 0.2407 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.2106 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0777 - mse: 0.0777 - mae: 0.2400 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.2089 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0783 - mse: 0.0783 - mae: 0.2399 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.2047 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0771 - mse: 0.0771 - mae: 0.2386 - val_loss: 0.0612 - val_mse: 0.0612 - val_mae: 0.2020 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0766 - mse: 0.0766 - mae: 0.2372 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.2034 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0616 - mse: 0.0616 - mae: 0.2060 - val_loss: 0.0349 - val_mse: 0.0349 - val_mae: 0.1481 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1596 - val_loss: 0.0469 - val_mse: 0.0469 - val_mae: 0.1810 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0351 - mse: 0.0351 - mae: 0.1497 - val_loss: 0.0427 - val_mse: 0.0427 - val_mae: 0.1708 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1477 - val_loss: 0.0445 - val_mse: 0.0445 - val_mae: 0.1787 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0347 - mse: 0.0347 - mae: 0.1502 - val_loss: 0.0440 - val_mse: 0.0440 - val_mae: 0.1753 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.0345 - mse: 0.0345 - mae: 0.1498 - val_loss: 0.0444 - val_mse: 0.0444 - val_mae: 0.1756 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1512 - val_loss: 0.0423 - val_mse: 0.0423 - val_mae: 0.1728 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0353 - mse: 0.0353 - mae: 0.1503 - val_loss: 0.0472 - val_mse: 0.0472 - val_mae: 0.1801 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0363 - mse: 0.0363 - mae: 0.1524 - val_loss: 0.0435 - val_mse: 0.0435 - val_mae: 0.1748 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1509 - val_loss: 0.0450 - val_mse: 0.0450 - val_mae: 0.1776 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1538 - val_loss: 0.0446 - val_mse: 0.0446 - val_mae: 0.1756 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1502 - val_loss: 0.0460 - val_mse: 0.0460 - val_mae: 0.1793 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.0358 - mse: 0.0358 - mae: 0.1511 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1808 - lr: 1.0000e-04\n",
      "Model B MSE: 0.04649817571043968\n",
      "Model B MAE: 0.18077322840690613\n",
      "Training model for category:  C\n",
      "Epoch 1/200\n",
      "70/70 [==============================] - 6s 46ms/step - loss: 0.1228 - mse: 0.1228 - mae: 0.2854 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1985 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0761 - mse: 0.0761 - mae: 0.2359 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1923 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0764 - mse: 0.0764 - mae: 0.2354 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1876 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0764 - mse: 0.0764 - mae: 0.2359 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1944 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0756 - mse: 0.0756 - mae: 0.2345 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.2042 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0754 - mse: 0.0754 - mae: 0.2346 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1916 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0761 - mse: 0.0761 - mae: 0.2349 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1905 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2348 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.2054 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0768 - mse: 0.0768 - mae: 0.2358 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1855 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0751 - mse: 0.0751 - mae: 0.2340 - val_loss: 0.0572 - val_mse: 0.0572 - val_mae: 0.1890 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0718 - mse: 0.0718 - mae: 0.2269 - val_loss: 0.0561 - val_mse: 0.0561 - val_mae: 0.1867 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0729 - mse: 0.0729 - mae: 0.2278 - val_loss: 0.0592 - val_mse: 0.0592 - val_mae: 0.1991 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0769 - mse: 0.0769 - mae: 0.2364 - val_loss: 0.0585 - val_mse: 0.0585 - val_mae: 0.1998 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0767 - mse: 0.0767 - mae: 0.2365 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1999 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2345 - val_loss: 0.0606 - val_mse: 0.0606 - val_mae: 0.2033 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0759 - mse: 0.0759 - mae: 0.2348 - val_loss: 0.0631 - val_mse: 0.0631 - val_mae: 0.2095 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0761 - mse: 0.0761 - mae: 0.2356 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.2201 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0753 - mse: 0.0753 - mae: 0.2338 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1881 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0761 - mse: 0.0761 - mae: 0.2355 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1887 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0747 - mse: 0.0747 - mae: 0.2336 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1945 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0745 - mse: 0.0745 - mae: 0.2332 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1950 - lr: 1.0000e-04\n",
      "Model C MSE: 0.05668610334396362\n",
      "Model C MAE: 0.1950390636920929\n",
      "Training model for category:  D\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 7s 47ms/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2430 - val_loss: 0.0619 - val_mse: 0.0619 - val_mae: 0.2070 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.2057 - val_loss: 0.0645 - val_mse: 0.0645 - val_mae: 0.2129 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1867 - val_loss: 0.0438 - val_mse: 0.0438 - val_mae: 0.1710 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0646 - mse: 0.0646 - mae: 0.2040 - val_loss: 0.0623 - val_mse: 0.0623 - val_mae: 0.2036 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1700 - val_loss: 0.0633 - val_mse: 0.0633 - val_mae: 0.2003 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0388 - mse: 0.0388 - mae: 0.1582 - val_loss: 0.0477 - val_mse: 0.0477 - val_mae: 0.1738 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1574 - val_loss: 0.0707 - val_mse: 0.0707 - val_mae: 0.2198 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0599 - mse: 0.0599 - mae: 0.2033 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.2104 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1960 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1839 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1861 - val_loss: 0.0602 - val_mse: 0.0602 - val_mae: 0.2015 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.2003 - val_loss: 0.0630 - val_mse: 0.0630 - val_mae: 0.2095 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.1973 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.2074 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1958 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.2038 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 3s 35ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.1945 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.2089 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 3s 36ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.1928 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.2072 - lr: 1.0000e-04\n",
      "Model D MSE: 0.06161854416131973\n",
      "Model D MAE: 0.20715494453907013\n",
      "Training model for category:  E\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 6s 51ms/step - loss: 0.1100 - mse: 0.1100 - mae: 0.2693 - val_loss: 0.1089 - val_mse: 0.1089 - val_mae: 0.2879 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.2147 - val_loss: 0.1275 - val_mse: 0.1275 - val_mae: 0.3153 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.2072 - val_loss: 0.0834 - val_mse: 0.0834 - val_mae: 0.2339 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0583 - mse: 0.0583 - mae: 0.1994 - val_loss: 0.0886 - val_mse: 0.0886 - val_mae: 0.2430 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 2s 38ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1811 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.2034 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1730 - val_loss: 0.1694 - val_mse: 0.1694 - val_mae: 0.3719 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0644 - mse: 0.0644 - mae: 0.2146 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1981 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0625 - mse: 0.0625 - mae: 0.2111 - val_loss: 0.0975 - val_mse: 0.0975 - val_mae: 0.2617 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2068 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2264 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.1944 - val_loss: 0.0731 - val_mse: 0.0731 - val_mae: 0.2161 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1680 - val_loss: 0.0792 - val_mse: 0.0792 - val_mae: 0.2319 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1798 - val_loss: 0.0818 - val_mse: 0.0818 - val_mae: 0.2374 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1713 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1709 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0634 - mse: 0.0634 - mae: 0.2025 - val_loss: 0.0723 - val_mse: 0.0723 - val_mae: 0.2232 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0615 - mse: 0.0615 - mae: 0.2096 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1953 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1835 - val_loss: 0.0806 - val_mse: 0.0806 - val_mae: 0.2416 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0615 - mse: 0.0615 - mae: 0.2088 - val_loss: 0.1163 - val_mse: 0.1163 - val_mae: 0.2988 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.0596 - mse: 0.0596 - mae: 0.2039 - val_loss: 0.0880 - val_mse: 0.0880 - val_mae: 0.2529 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.2018 - val_loss: 0.0881 - val_mse: 0.0881 - val_mae: 0.2524 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.1891 - val_loss: 0.0738 - val_mse: 0.0738 - val_mae: 0.2160 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0575 - mse: 0.0575 - mae: 0.1960 - val_loss: 0.1005 - val_mse: 0.1005 - val_mae: 0.2730 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0648 - mse: 0.0648 - mae: 0.2167 - val_loss: 0.0961 - val_mse: 0.0961 - val_mae: 0.2644 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0627 - mse: 0.0627 - mae: 0.2117 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2724 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.2077 - val_loss: 0.0956 - val_mse: 0.0956 - val_mae: 0.2630 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2073 - val_loss: 0.0986 - val_mse: 0.0986 - val_mae: 0.2681 - lr: 1.0000e-04\n",
      "Model E MSE: 0.09856992959976196\n",
      "Model E MAE: 0.2680624723434448\n",
      "Training model for category:  F\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 4s 821ms/step - loss: 0.3906 - mse: 0.3906 - mae: 0.5350 - val_loss: 0.2677 - val_mse: 0.2677 - val_mae: 0.4810 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3466 - mse: 0.3466 - mae: 0.5101 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4862 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3129 - mse: 0.3129 - mae: 0.4840 - val_loss: 0.2330 - val_mse: 0.2330 - val_mae: 0.4516 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2723 - mse: 0.2723 - mae: 0.4508 - val_loss: 0.1810 - val_mse: 0.1810 - val_mae: 0.3949 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2188 - mse: 0.2188 - mae: 0.4056 - val_loss: 0.1204 - val_mse: 0.1204 - val_mae: 0.3181 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1621 - mse: 0.1621 - mae: 0.3527 - val_loss: 0.0812 - val_mse: 0.0812 - val_mae: 0.2183 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1171 - mse: 0.1171 - mae: 0.2959 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2502 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1088 - mse: 0.1088 - mae: 0.2753 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1821 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2554 - val_loss: 0.0457 - val_mse: 0.0457 - val_mae: 0.1329 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1084 - mse: 0.1084 - mae: 0.2732 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1470 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1069 - mse: 0.1069 - mae: 0.2650 - val_loss: 0.0784 - val_mse: 0.0784 - val_mae: 0.1987 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1084 - mse: 0.1084 - mae: 0.2566 - val_loss: 0.0748 - val_mse: 0.0748 - val_mae: 0.1945 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1018 - mse: 0.1018 - mae: 0.2549 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1520 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0976 - mse: 0.0976 - mae: 0.2608 - val_loss: 0.0488 - val_mse: 0.0488 - val_mae: 0.1491 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2630 - val_loss: 0.0592 - val_mse: 0.0592 - val_mae: 0.1732 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0936 - mse: 0.0936 - mae: 0.2614 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.1990 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0969 - mse: 0.0969 - mae: 0.2634 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.1889 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0935 - mse: 0.0935 - mae: 0.2627 - val_loss: 0.0518 - val_mse: 0.0518 - val_mae: 0.1619 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0963 - mse: 0.0963 - mae: 0.2708 - val_loss: 0.0470 - val_mse: 0.0470 - val_mae: 0.1600 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0988 - mse: 0.0988 - mae: 0.2750 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1597 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2739 - val_loss: 0.0482 - val_mse: 0.0482 - val_mae: 0.1590 - lr: 1.0000e-04\n",
      "Model F MSE: 0.04817850887775421\n",
      "Model F MAE: 0.15898267924785614\n"
     ]
    }
   ],
   "source": [
    "train_models(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
